"""Describe the Haddock3 ontology used for communicating between modules."""
import datetime
import itertools
import os
import re
from enum import Enum
from os import linesep
from os.path import getmtime
from pathlib import Path

import jsonpickle

from haddock.core.defaults import MODULE_IO_FILE
from haddock.core.typing import (
    Any,
    FilePath,
    List,
    Optional,
    TypeVar,
    Union,
    )
from haddock.libs import libpdb


NaN = float("nan")


class Format(Enum):
    """Input and Output possible formats."""

    PDB = "pdb"
    PDB_ENSEMBLE = "pdb"
    CNS_INPUT = "inp"
    CNS_OUTPUT = "out"
    TOPOLOGY = "psf"
    MATRIX = "matrix"

    def __str__(self) -> str:
        return str(self.value)


class Persistent:
    """Any persistent file generated by this framework."""

    def __init__(
            self,
            file_name: FilePath,
            file_type: Format,
            path: FilePath = ".",
            md5: Optional[str] = None,
            restr_fname: Optional[FilePath] = None,
            ) -> None:
        self.created = datetime.datetime.now().isoformat(" ", "seconds")
        self.file_name = Path(file_name).name
        self.file_type = file_type
        self.path = str(Path(path).resolve())
        self.full_name = str(Path(path, self.file_name))
        self.rel_path = Path("..", Path(self.path).name, file_name)
        self.md5 = md5
        self.restr_fname = restr_fname

    def __repr__(self) -> str:
        rep = (
            f"[{self.file_type}|{self.created}] "
            f"{Path(self.path) / self.file_name}"
            )
        return rep

    def is_present(self) -> bool:
        """Check if the persisent file exists on disk."""
        return self.rel_path.resolve().exists()


class PDBFile(Persistent):
    """Represent a PDB file."""

    def __init__(
            self,
            file_name: Union[Path, str],
            topology: Optional[Any] = None,
            path: Union[Path, str] = ".",
            score: float = NaN,
            md5: Optional[str] = None,
            restr_fname: Optional[Union[Path, str]] = None,
            unw_energies: Optional[dict[str, float]] = None,
            ) -> None:
        super().__init__(file_name, Format.PDB, path, md5, restr_fname)

        self.topology = topology
        self.score = score
        self.ori_name: Optional[str] = None
        self.clt_id: Union[str, int, None] = None
        self.clt_rank: Optional[int] = None
        self.clt_model_rank: Optional[int] = None
        self.len = score
        self.unw_energies = unw_energies

    def __lt__(self, other: "PDBFile") -> bool:
        return self.score < other.score

    def __gt__(self, other: "PDBFile") -> bool:
        return self.score > other.score

    def __eq__(self, other: "PDBFile") -> bool:  # type: ignore
        return self.score == other.score

    def __hash__(self) -> int:
        return id(self)


class RMSDFile(Persistent):
    """Represents a RMSD matrix file."""

    def __init__(
            self,
            file_name: FilePath,
            npairs: int,
            path: FilePath = ".",
            ) -> None:
        super().__init__(file_name, Format.MATRIX, path)
        self.npairs = npairs

    def __hash__(self) -> int:
        return id(self)


class TopologyFile(Persistent):
    """Represent a CNS-generated topology file."""

    def __init__(self, file_name: FilePath, path: FilePath = ".") -> None:
        super().__init__(file_name, Format.TOPOLOGY, path)


class ModuleIO:
    """Intercommunicating modules and exchange input/output information."""

    def __init__(self) -> None:
        self.input: List[Any] = []
        self.output: List[Any] = []

    def add(self, persistent, mode="i"):
        """Add a given filename as input or output."""
        if mode == "i":
            if isinstance(persistent, list):
                self.input.extend(persistent)
            else:
                self.input.append(persistent)
        else:
            if isinstance(persistent, list):
                self.output.extend(persistent)
            else:
                self.output.append(persistent)

    def save(
            self,
            path: FilePath = ".",
            filename: FilePath = MODULE_IO_FILE,
            ) -> Path:
        """Save Input/Output needed files by this module to disk."""
        fpath = Path(path, filename)
        with open(fpath, "w") as output_handler:
            to_save = {"input": self.input, "output": self.output}
            jsonpickle.set_encoder_options("json", sort_keys=True, indent=4)
            output_handler.write(jsonpickle.encode(to_save))  # type: ignore
        return fpath

    def load(self, filename: FilePath) -> None:
        """Load the content of a given IO filename."""
        if filename.is_file():
            with open(filename) as json_file:
                content = jsonpickle.decode(json_file.read())
                self.input = content["input"]  # type: ignore
                self.output = content["output"]  # type: ignore

    def retrieve_models(
            self, crossdock: bool = False, individualize: bool = False
            ) -> list[Union[PDBFile, list[PDBFile]]]:
        """Retrieve the PDBobjects to be used in the module."""
        # Get the models generated in previous step
        model_list: list[PDBFile] = []
        input_dic: dict[int, list[PDBFile]] = {}

        for i, element in enumerate(self.output):
            if isinstance(element, dict):
                position_list: list[PDBFile] = input_dic.setdefault(i, [])
                for key in element:
                    position_list.append(element[key])  # type: ignore

            elif element.file_type == Format.PDB:  # type: ignore
                model_list.append(element)  # type: ignore
        if input_dic and not crossdock and not individualize:
            # check if all ensembles contain the same number of models
            sub_lists = iter(input_dic.values())
            _len = len(next(sub_lists))
            if not all(len(sub) == _len for sub in sub_lists):
                _msg = (
                    "Different number of models in molecules,"
                    " cannot prepare pairwise complexes."
                    )
                raise Exception(_msg)

            # prepare pairwise combinations
            model_list = [
                values for values in zip(*input_dic.values())
                ]  # type: ignore
        elif input_dic and crossdock and not individualize:
            model_list = [
                values for values in itertools.product(*input_dic.values())
                ]  # type: ignore
        elif input_dic and individualize:
            model_list = list(itertools.chain(*input_dic.values()))

        return model_list  # type: ignore

    def check_faulty(self) -> float:
        """Check how many of the output exists."""
        total = 0.0
        present = 0.0
        for element in self.output:
            if isinstance(element, dict):
                total += len(element)
                present += sum(j.is_present() for j in element.values())
            else:
                total += 1
                if element.is_present():
                    present += 1

        if total == 0:
            _msg = "No expected output was passed to ModuleIO"
            raise Exception(_msg)

        faulty_per = (1 - (present / total)) * 100

        # added this method here to avoid modifying all calls in the
        # modules' run method. We can think about restructure this part
        # in the future.
        self.remove_missing()

        return faulty_per

    def remove_missing(self) -> None:
        """Remove missing structure from `output`."""
        # can't modify a list/dictionary within a loop
        idxs: list[int] = []
        for idx, element in enumerate(self.output):
            if isinstance(element, dict):
                to_pop = []
                for key2 in element:
                    if not element[key2].is_present():
                        to_pop.append(key2)
                for pop_me in to_pop:
                    element.pop(pop_me)
            else:
                if not element.is_present():
                    idxs.append(idx)

        self.output = [
            value for i, value in enumerate(self.output)
            if i not in idxs
            ]

    def __repr__(self) -> str:
        return f"Input: {self.input}{linesep}Output: {self.output}"

    def load_from_input_molecules(
            self,
            input_molecules_dir: Path,
            ) -> None:
        """Load first molecules at the stat of the workflow.

        Parameters
        ----------
        input_molecules_dir : Path
            Directory where the input molecules are stored.
        """
        # Gather all input molecules
        input_molecules = list(input_molecules_dir.glob('*.pdb'))
        # Sort them by creation date (which is also input order)
        input_molecules.sort(key=getmtime)  # FIXME: getctime ?
        # Set input attribute
        self.input = input_molecules

        # Set parsing variables
        molecules_dic: dict[int, dict[int, PDBFile]] = {}
        # Loop over input molecules
        for i, molecule in enumerate(self.input, start=1):
            # Split models (these come already sorted)
            splited_models = libpdb.split_ensemble(
                molecule,
                dest=input_molecules_dir,
                )
            # get the MD5 hash of each model
            md5_dic = self.get_md5(molecule)
            origin_names = self.get_ensemble_origin(molecule)
            # Initiate with empty list
            molecules_dic.setdefault(i, {})
            # Loop over conformers of this ensemble
            for j, model in enumerate(splited_models):
                processed_model = model
                model_name = model.stem
                # Search of md5 information
                md5_hash = None
                try:
                    model_id = int(model_name.split("_")[-1])
                except ValueError:
                    model_id = 0
                if model_id in md5_dic:
                    md5_hash = md5_dic[model_id]
                # Check if origin or md5 is available
                if md5_hash or model_id in origin_names.keys():
                    # Select prefix
                    if md5_hash:  # Prioritize the md5 hash
                        prefix_name = md5_hash
                    else:
                        prefix_name = origin_names[model_id]
                    # Build new filename
                    model_new_name = f"{prefix_name}_from_{model_name}"
                    # Rename file
                    processed_model = model.rename(
                        Path(
                            input_molecules_dir,
                            f"{model_new_name}.{Format.PDB}",
                            )
                        )
                # Create a PDBFile object
                pdbfile = PDBFile(
                    processed_model,
                    md5=md5_hash,
                    )
                # Modify relative path attribute
                pdbfile.rel_path = Path(
                    "..",
                    input_molecules_dir,
                    pdbfile.file_name
                    )
                # Set origin name
                pdbfile.ori_name = molecule
                # Hold that conformer/model
                molecules_dic[i][j] = pdbfile
        # And fake them to be the output of the previous io
        self.output = list(molecules_dic.values())
    
    @staticmethod
    def get_md5(ensemble_f: FilePath) -> dict[int, str]:
        """Get MD5 hash of a multi-model PDB file."""
        md5_dic: dict[int, str] = {}
        text = Path(ensemble_f).read_text()
        lines = text.split(os.linesep)
        REMARK_lines = (line for line in lines if line.startswith("REMARK"))
        remd5 = re.compile(r"^[a-f0-9]{32}$")
        for line in REMARK_lines:
            parts = line.strip().split()

            try:
                idx = parts.index("MODEL")
            except ValueError:  # MODEL not in parts, this line can be ignored
                continue

            # check if there's a md5 hash in line
            for part in parts:
                group = remd5.fullmatch(part)
                if group:
                    # the model num comes after the MODEL
                    model_num = int(parts[idx + 1])
                    md5_dic[model_num] = group.string  # md5 hash
                    break

        return md5_dic
    
    @staticmethod
    def get_ensemble_origin(ensemble_f: FilePath) -> dict[int, str]:
        """Try to find origin for each model in ensemble.

        Parameters
        ----------
        ensemble_f : FilePath
            Path to a pdb file containing an ensemble.

        Returns
        -------
        origin_dic : dict[int, str]
            Dictionary holding as keys the modelID and values its origin.
        """
        origin_dic: dict[int, str] = {}
        text = Path(ensemble_f).read_text()
        lines = text.split(os.linesep)
        REMARK_lines = (line for line in lines if line.startswith("REMARK"))
        re_origin = re.compile(
            r"REMARK\s+MODEL\s+(\d+)\s+(FROM|from|From)\s+(([\w_-]+\.?)+)"
            )
        for line in REMARK_lines:
            if (match := re_origin.search(line)):
                model_num = int(match.group(1).strip())
                original_path = match.group(3).strip()
                original_name = Path(original_path).stem
                origin_dic[model_num] = original_name
        return origin_dic


PDBPath = Union[PDBFile, Path]

PDBPathT = TypeVar("PDBPathT", bound=Union[PDBFile, Path])
"""
Generic type variable for PDBFile or Path.

If the first annotated variable is PDBFile,
the second annotated variable will be PDBFile instead of Path,vice versa.
"""
